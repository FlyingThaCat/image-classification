{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c276c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Requirement already satisfied: torch in ./.conda/lib/python3.11/site-packages (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in ./.conda/lib/python3.11/site-packages (0.22.1+cu128)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.conda/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.conda/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in ./.conda/lib/python3.11/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in ./.conda/lib/python3.11/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in ./.conda/lib/python3.11/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in ./.conda/lib/python3.11/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in ./.conda/lib/python3.11/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.conda/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.conda/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in ./.conda/lib/python3.11/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.conda/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.conda/lib/python3.11/site-packages (from triton==3.3.1->torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e35430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eabdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a97d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('./colored_images', transform=transform)\n",
    "\n",
    "class_names = dataset.classes\n",
    "print(f\"Labels: {class_names}\")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=24, pin_memory=True, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=24, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a8e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Developer/diabetic-retinopathy/.conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/john/Developer/diabetic-retinopathy/.conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "# for param in densenet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    densenet.features,\n",
    "    nn.AdaptiveAvgPool2d((7, 7))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d74e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121ToLSTM(nn.Module):\n",
    "    def __init__(self, lstm_hidden_size=129, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.features = feature_extractor\n",
    "        self.lstm = nn.LSTM(input_size=49, hidden_size=lstm_hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 1024, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        \n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c72f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121ToLSTM(num_classes=5).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fee7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.8730, Accuracy: 69.43%\n",
      "Epoch [2/300], Loss: 0.6985, Accuracy: 72.14%\n",
      "Epoch [3/300], Loss: 0.6742, Accuracy: 73.37%\n",
      "Epoch [4/300], Loss: 0.6295, Accuracy: 74.10%\n",
      "Epoch [5/300], Loss: 0.6146, Accuracy: 74.53%\n",
      "Epoch [6/300], Loss: 0.5662, Accuracy: 75.20%\n",
      "Epoch [7/300], Loss: 0.5390, Accuracy: 75.82%\n",
      "Epoch [8/300], Loss: 0.5221, Accuracy: 76.31%\n",
      "Epoch [9/300], Loss: 0.4963, Accuracy: 76.82%\n",
      "Epoch [10/300], Loss: 0.4624, Accuracy: 77.39%\n",
      "Epoch [11/300], Loss: 0.4326, Accuracy: 77.96%\n",
      "Epoch [12/300], Loss: 0.4105, Accuracy: 78.49%\n",
      "Epoch [13/300], Loss: 0.3796, Accuracy: 79.01%\n",
      "Epoch [14/300], Loss: 0.3491, Accuracy: 79.55%\n",
      "Epoch [15/300], Loss: 0.3235, Accuracy: 80.11%\n",
      "Epoch [16/300], Loss: 0.2875, Accuracy: 80.72%\n",
      "Epoch [17/300], Loss: 0.2548, Accuracy: 81.31%\n",
      "Epoch [18/300], Loss: 0.2212, Accuracy: 81.93%\n",
      "Epoch [19/300], Loss: 0.1896, Accuracy: 82.52%\n",
      "Epoch [20/300], Loss: 0.1853, Accuracy: 83.06%\n",
      "Epoch [21/300], Loss: 0.1550, Accuracy: 83.59%\n",
      "Epoch [22/300], Loss: 0.1381, Accuracy: 84.11%\n",
      "Epoch [23/300], Loss: 0.1233, Accuracy: 84.61%\n",
      "Epoch [24/300], Loss: 0.1135, Accuracy: 85.07%\n",
      "Epoch [25/300], Loss: 0.1399, Accuracy: 85.48%\n",
      "Epoch [26/300], Loss: 0.1040, Accuracy: 85.90%\n",
      "Epoch [27/300], Loss: 0.0851, Accuracy: 86.31%\n",
      "Epoch [28/300], Loss: 0.1152, Accuracy: 86.65%\n",
      "Epoch [29/300], Loss: 0.0950, Accuracy: 86.99%\n",
      "Epoch [30/300], Loss: 0.0692, Accuracy: 87.35%\n",
      "Epoch [31/300], Loss: 0.0562, Accuracy: 87.70%\n",
      "Epoch [32/300], Loss: 0.0536, Accuracy: 88.02%\n",
      "Epoch [33/300], Loss: 0.0649, Accuracy: 88.31%\n",
      "Epoch [34/300], Loss: 0.0501, Accuracy: 88.60%\n",
      "Epoch [35/300], Loss: 0.0843, Accuracy: 88.83%\n",
      "Epoch [36/300], Loss: 0.0504, Accuracy: 89.10%\n",
      "Epoch [37/300], Loss: 0.0698, Accuracy: 89.32%\n",
      "Epoch [38/300], Loss: 0.0556, Accuracy: 89.55%\n",
      "Epoch [39/300], Loss: 0.0449, Accuracy: 89.78%\n",
      "Epoch [40/300], Loss: 0.0394, Accuracy: 90.00%\n",
      "Epoch [41/300], Loss: 0.0527, Accuracy: 90.19%\n",
      "Epoch [42/300], Loss: 0.0770, Accuracy: 90.35%\n",
      "Epoch [43/300], Loss: 0.0787, Accuracy: 90.51%\n",
      "Epoch [44/300], Loss: 0.0548, Accuracy: 90.68%\n",
      "Epoch [45/300], Loss: 0.0318, Accuracy: 90.85%\n",
      "Epoch [46/300], Loss: 0.0272, Accuracy: 91.02%\n",
      "Epoch [47/300], Loss: 0.0368, Accuracy: 91.18%\n",
      "Epoch [48/300], Loss: 0.0717, Accuracy: 91.31%\n",
      "Epoch [49/300], Loss: 0.0625, Accuracy: 91.43%\n",
      "Epoch [50/300], Loss: 0.0255, Accuracy: 91.58%\n",
      "Epoch [51/300], Loss: 0.0195, Accuracy: 91.72%\n",
      "Epoch [52/300], Loss: 0.0170, Accuracy: 91.86%\n",
      "Epoch [53/300], Loss: 0.0179, Accuracy: 92.00%\n",
      "Epoch [54/300], Loss: 0.0168, Accuracy: 92.12%\n",
      "Epoch [55/300], Loss: 0.0174, Accuracy: 92.25%\n",
      "Epoch [56/300], Loss: 0.0887, Accuracy: 92.33%\n",
      "Epoch [57/300], Loss: 0.0719, Accuracy: 92.42%\n",
      "Epoch [58/300], Loss: 0.0368, Accuracy: 92.52%\n",
      "Epoch [59/300], Loss: 0.0416, Accuracy: 92.62%\n",
      "Epoch [60/300], Loss: 0.0672, Accuracy: 92.70%\n",
      "Epoch [61/300], Loss: 0.0688, Accuracy: 92.77%\n",
      "Epoch [62/300], Loss: 0.0467, Accuracy: 92.86%\n",
      "Epoch [63/300], Loss: 0.0373, Accuracy: 92.94%\n",
      "Epoch [64/300], Loss: 0.0258, Accuracy: 93.03%\n",
      "Epoch [65/300], Loss: 0.0343, Accuracy: 93.11%\n",
      "Epoch [66/300], Loss: 0.0297, Accuracy: 93.19%\n",
      "Epoch [67/300], Loss: 0.0310, Accuracy: 93.28%\n",
      "Epoch [68/300], Loss: 0.0441, Accuracy: 93.34%\n",
      "Epoch [69/300], Loss: 0.0446, Accuracy: 93.42%\n",
      "Epoch [70/300], Loss: 0.0922, Accuracy: 93.46%\n",
      "Epoch [71/300], Loss: 0.0362, Accuracy: 93.53%\n",
      "Epoch [72/300], Loss: 0.0304, Accuracy: 93.60%\n",
      "Epoch [73/300], Loss: 0.0288, Accuracy: 93.67%\n",
      "Epoch [74/300], Loss: 0.0233, Accuracy: 93.74%\n",
      "Epoch [75/300], Loss: 0.0195, Accuracy: 93.81%\n",
      "Epoch [76/300], Loss: 0.0199, Accuracy: 93.88%\n",
      "Epoch [77/300], Loss: 0.0178, Accuracy: 93.94%\n",
      "Epoch [78/300], Loss: 0.0168, Accuracy: 94.01%\n",
      "Epoch [79/300], Loss: 0.0443, Accuracy: 94.06%\n",
      "Epoch [80/300], Loss: 0.1002, Accuracy: 94.09%\n",
      "Epoch [81/300], Loss: 0.0368, Accuracy: 94.15%\n",
      "Epoch [82/300], Loss: 0.0163, Accuracy: 94.20%\n",
      "Epoch [83/300], Loss: 0.0151, Accuracy: 94.26%\n",
      "Epoch [84/300], Loss: 0.0160, Accuracy: 94.32%\n",
      "Epoch [85/300], Loss: 0.0399, Accuracy: 94.36%\n",
      "Epoch [86/300], Loss: 0.0309, Accuracy: 94.41%\n",
      "Epoch [87/300], Loss: 0.0372, Accuracy: 94.46%\n",
      "Epoch [88/300], Loss: 0.0325, Accuracy: 94.50%\n",
      "Epoch [89/300], Loss: 0.0648, Accuracy: 94.54%\n",
      "Epoch [90/300], Loss: 0.0394, Accuracy: 94.58%\n",
      "Epoch [91/300], Loss: 0.0168, Accuracy: 94.63%\n",
      "Epoch [92/300], Loss: 0.0187, Accuracy: 94.67%\n",
      "Epoch [93/300], Loss: 0.0152, Accuracy: 94.72%\n",
      "Epoch [94/300], Loss: 0.0136, Accuracy: 94.76%\n",
      "Epoch [95/300], Loss: 0.0128, Accuracy: 94.81%\n",
      "Epoch [96/300], Loss: 0.0123, Accuracy: 94.85%\n",
      "Epoch [97/300], Loss: 0.0125, Accuracy: 94.90%\n",
      "Epoch [98/300], Loss: 0.0130, Accuracy: 94.94%\n",
      "Epoch [99/300], Loss: 0.0122, Accuracy: 94.98%\n",
      "Epoch [100/300], Loss: 0.0124, Accuracy: 95.02%\n",
      "Epoch [101/300], Loss: 0.0124, Accuracy: 95.06%\n",
      "Epoch [102/300], Loss: 0.0122, Accuracy: 95.10%\n",
      "Epoch [103/300], Loss: 0.0126, Accuracy: 95.13%\n",
      "Epoch [104/300], Loss: 0.0127, Accuracy: 95.17%\n",
      "Epoch [105/300], Loss: 0.0122, Accuracy: 95.21%\n",
      "Epoch [106/300], Loss: 0.0123, Accuracy: 95.24%\n",
      "Epoch [107/300], Loss: 0.0119, Accuracy: 95.28%\n",
      "Epoch [108/300], Loss: 0.0118, Accuracy: 95.31%\n",
      "Epoch [109/300], Loss: 0.0120, Accuracy: 95.35%\n",
      "Epoch [110/300], Loss: 0.0124, Accuracy: 95.38%\n",
      "Epoch [111/300], Loss: 0.0250, Accuracy: 95.41%\n",
      "Epoch [112/300], Loss: 0.1967, Accuracy: 95.39%\n",
      "Epoch [113/300], Loss: 0.0695, Accuracy: 95.41%\n",
      "Epoch [114/300], Loss: 0.0459, Accuracy: 95.43%\n",
      "Epoch [115/300], Loss: 0.0368, Accuracy: 95.46%\n",
      "Epoch [116/300], Loss: 0.0250, Accuracy: 95.49%\n",
      "Epoch [117/300], Loss: 0.0259, Accuracy: 95.51%\n",
      "Epoch [118/300], Loss: 0.0174, Accuracy: 95.54%\n",
      "Epoch [119/300], Loss: 0.0172, Accuracy: 95.57%\n",
      "Epoch [120/300], Loss: 0.0174, Accuracy: 95.60%\n",
      "Epoch [121/300], Loss: 0.0426, Accuracy: 95.62%\n",
      "Epoch [122/300], Loss: 0.0714, Accuracy: 95.63%\n",
      "Epoch [123/300], Loss: 0.0322, Accuracy: 95.65%\n",
      "Epoch [124/300], Loss: 0.0353, Accuracy: 95.67%\n",
      "Epoch [125/300], Loss: 0.0371, Accuracy: 95.69%\n",
      "Epoch [126/300], Loss: 0.0385, Accuracy: 95.71%\n",
      "Epoch [127/300], Loss: 0.0192, Accuracy: 95.74%\n",
      "Epoch [128/300], Loss: 0.0177, Accuracy: 95.76%\n",
      "Epoch [129/300], Loss: 0.0339, Accuracy: 95.78%\n",
      "Epoch [130/300], Loss: 0.0205, Accuracy: 95.80%\n",
      "Epoch [131/300], Loss: 0.0159, Accuracy: 95.83%\n",
      "Epoch [132/300], Loss: 0.0137, Accuracy: 95.85%\n",
      "Epoch [133/300], Loss: 0.0126, Accuracy: 95.88%\n",
      "Epoch [134/300], Loss: 0.0161, Accuracy: 95.90%\n",
      "Epoch [135/300], Loss: 0.0134, Accuracy: 95.92%\n",
      "Epoch [136/300], Loss: 0.0195, Accuracy: 95.94%\n",
      "Epoch [137/300], Loss: 0.0272, Accuracy: 95.96%\n",
      "Epoch [138/300], Loss: 0.0189, Accuracy: 95.98%\n",
      "Epoch [139/300], Loss: 0.0139, Accuracy: 96.01%\n",
      "Epoch [140/300], Loss: 0.0166, Accuracy: 96.03%\n",
      "Epoch [141/300], Loss: 0.0245, Accuracy: 96.05%\n",
      "Epoch [142/300], Loss: 0.0182, Accuracy: 96.07%\n",
      "Epoch [143/300], Loss: 0.0186, Accuracy: 96.09%\n",
      "Epoch [144/300], Loss: 0.0658, Accuracy: 96.09%\n",
      "Epoch [145/300], Loss: 0.1013, Accuracy: 96.10%\n",
      "Epoch [146/300], Loss: 0.0210, Accuracy: 96.11%\n",
      "Epoch [147/300], Loss: 0.0156, Accuracy: 96.13%\n",
      "Epoch [148/300], Loss: 0.0131, Accuracy: 96.15%\n",
      "Epoch [149/300], Loss: 0.0131, Accuracy: 96.17%\n",
      "Epoch [150/300], Loss: 0.0141, Accuracy: 96.19%\n",
      "Epoch [151/300], Loss: 0.0122, Accuracy: 96.21%\n",
      "Epoch [152/300], Loss: 0.0118, Accuracy: 96.23%\n",
      "Epoch [153/300], Loss: 0.0120, Accuracy: 96.25%\n",
      "Epoch [154/300], Loss: 0.0141, Accuracy: 96.26%\n",
      "Epoch [155/300], Loss: 0.0126, Accuracy: 96.28%\n",
      "Epoch [156/300], Loss: 0.0119, Accuracy: 96.30%\n",
      "Epoch [157/300], Loss: 0.0117, Accuracy: 96.31%\n",
      "Epoch [158/300], Loss: 0.0116, Accuracy: 96.33%\n",
      "Epoch [159/300], Loss: 0.0116, Accuracy: 96.35%\n",
      "Epoch [160/300], Loss: 0.0115, Accuracy: 96.37%\n",
      "Epoch [161/300], Loss: 0.0116, Accuracy: 96.38%\n",
      "Epoch [162/300], Loss: 0.0115, Accuracy: 96.40%\n",
      "Epoch [163/300], Loss: 0.0116, Accuracy: 96.42%\n",
      "Epoch [164/300], Loss: 0.0119, Accuracy: 96.43%\n",
      "Epoch [165/300], Loss: 0.0116, Accuracy: 96.45%\n",
      "Epoch [166/300], Loss: 0.0114, Accuracy: 96.46%\n",
      "Epoch [167/300], Loss: 0.0116, Accuracy: 96.48%\n",
      "Epoch [168/300], Loss: 0.0113, Accuracy: 96.49%\n",
      "Epoch [169/300], Loss: 0.0113, Accuracy: 96.51%\n",
      "Epoch [170/300], Loss: 0.0111, Accuracy: 96.52%\n",
      "Epoch [171/300], Loss: 0.0118, Accuracy: 96.54%\n",
      "Epoch [172/300], Loss: 0.0114, Accuracy: 96.55%\n",
      "Epoch [173/300], Loss: 0.0123, Accuracy: 96.57%\n",
      "Epoch [174/300], Loss: 0.0506, Accuracy: 96.58%\n",
      "Epoch [175/300], Loss: 0.1535, Accuracy: 96.56%\n",
      "Epoch [176/300], Loss: 0.0579, Accuracy: 96.57%\n",
      "Epoch [177/300], Loss: 0.0427, Accuracy: 96.58%\n",
      "Epoch [178/300], Loss: 0.0214, Accuracy: 96.59%\n",
      "Epoch [179/300], Loss: 0.0233, Accuracy: 96.60%\n",
      "Epoch [180/300], Loss: 0.0295, Accuracy: 96.62%\n",
      "Epoch [181/300], Loss: 0.0161, Accuracy: 96.63%\n",
      "Epoch [182/300], Loss: 0.0185, Accuracy: 96.64%\n",
      "Epoch [183/300], Loss: 0.0128, Accuracy: 96.65%\n",
      "Epoch [184/300], Loss: 0.0160, Accuracy: 96.67%\n",
      "Epoch [185/300], Loss: 0.0424, Accuracy: 96.68%\n",
      "Epoch [186/300], Loss: 0.0230, Accuracy: 96.69%\n",
      "Epoch [187/300], Loss: 0.0447, Accuracy: 96.69%\n",
      "Epoch [188/300], Loss: 0.0295, Accuracy: 96.70%\n",
      "Epoch [189/300], Loss: 0.0173, Accuracy: 96.72%\n",
      "Epoch [190/300], Loss: 0.0137, Accuracy: 96.73%\n",
      "Epoch [191/300], Loss: 0.0157, Accuracy: 96.74%\n",
      "Epoch [192/300], Loss: 0.0130, Accuracy: 96.75%\n",
      "Epoch [193/300], Loss: 0.0119, Accuracy: 96.76%\n",
      "Epoch [194/300], Loss: 0.0116, Accuracy: 96.78%\n",
      "Epoch [195/300], Loss: 0.0130, Accuracy: 96.79%\n",
      "Epoch [196/300], Loss: 0.0298, Accuracy: 96.80%\n",
      "Epoch [197/300], Loss: 0.0457, Accuracy: 96.80%\n",
      "Epoch [198/300], Loss: 0.0251, Accuracy: 96.81%\n",
      "Epoch [199/300], Loss: 0.0271, Accuracy: 96.82%\n",
      "Epoch [200/300], Loss: 0.0264, Accuracy: 96.83%\n",
      "Epoch [201/300], Loss: 0.0241, Accuracy: 96.84%\n",
      "Epoch [202/300], Loss: 0.0197, Accuracy: 96.85%\n",
      "Epoch [203/300], Loss: 0.0166, Accuracy: 96.86%\n",
      "Epoch [204/300], Loss: 0.0290, Accuracy: 96.87%\n",
      "Epoch [205/300], Loss: 0.0166, Accuracy: 96.88%\n",
      "Epoch [206/300], Loss: 0.0121, Accuracy: 96.89%\n",
      "Epoch [207/300], Loss: 0.0122, Accuracy: 96.90%\n",
      "Epoch [208/300], Loss: 0.0117, Accuracy: 96.91%\n",
      "Epoch [209/300], Loss: 0.0114, Accuracy: 96.92%\n",
      "Epoch [210/300], Loss: 0.0113, Accuracy: 96.93%\n",
      "Epoch [211/300], Loss: 0.0115, Accuracy: 96.94%\n",
      "Epoch [212/300], Loss: 0.0115, Accuracy: 96.95%\n",
      "Epoch [213/300], Loss: 0.0116, Accuracy: 96.96%\n",
      "Epoch [214/300], Loss: 0.0114, Accuracy: 96.97%\n",
      "Epoch [215/300], Loss: 0.0113, Accuracy: 96.98%\n",
      "Epoch [216/300], Loss: 0.0117, Accuracy: 96.99%\n",
      "Epoch [217/300], Loss: 0.0111, Accuracy: 97.00%\n",
      "Epoch [218/300], Loss: 0.0113, Accuracy: 97.01%\n",
      "Epoch [219/300], Loss: 0.0279, Accuracy: 97.01%\n",
      "Epoch [220/300], Loss: 0.1112, Accuracy: 97.01%\n",
      "Epoch [221/300], Loss: 0.0556, Accuracy: 97.01%\n",
      "Epoch [222/300], Loss: 0.0192, Accuracy: 97.02%\n",
      "Epoch [223/300], Loss: 0.0236, Accuracy: 97.03%\n",
      "Epoch [224/300], Loss: 0.0397, Accuracy: 97.04%\n",
      "Epoch [225/300], Loss: 0.0335, Accuracy: 97.04%\n",
      "Epoch [226/300], Loss: 0.0207, Accuracy: 97.05%\n",
      "Epoch [227/300], Loss: 0.0190, Accuracy: 97.06%\n",
      "Epoch [228/300], Loss: 0.0135, Accuracy: 97.07%\n",
      "Epoch [229/300], Loss: 0.0118, Accuracy: 97.08%\n",
      "Epoch [230/300], Loss: 0.0120, Accuracy: 97.08%\n",
      "Epoch [231/300], Loss: 0.0129, Accuracy: 97.09%\n",
      "Epoch [232/300], Loss: 0.0148, Accuracy: 97.10%\n",
      "Epoch [233/300], Loss: 0.0169, Accuracy: 97.11%\n",
      "Epoch [234/300], Loss: 0.0140, Accuracy: 97.12%\n",
      "Epoch [235/300], Loss: 0.0117, Accuracy: 97.12%\n",
      "Epoch [236/300], Loss: 0.0119, Accuracy: 97.13%\n",
      "Epoch [237/300], Loss: 0.0117, Accuracy: 97.14%\n",
      "Epoch [238/300], Loss: 0.0126, Accuracy: 97.15%\n",
      "Epoch [239/300], Loss: 0.0232, Accuracy: 97.15%\n",
      "Epoch [240/300], Loss: 0.0249, Accuracy: 97.16%\n",
      "Epoch [241/300], Loss: 0.0397, Accuracy: 97.17%\n",
      "Epoch [242/300], Loss: 0.0595, Accuracy: 97.17%\n",
      "Epoch [243/300], Loss: 0.0199, Accuracy: 97.17%\n",
      "Epoch [244/300], Loss: 0.0148, Accuracy: 97.18%\n",
      "Epoch [245/300], Loss: 0.0135, Accuracy: 97.19%\n",
      "Epoch [246/300], Loss: 0.0119, Accuracy: 97.20%\n",
      "Epoch [247/300], Loss: 0.0123, Accuracy: 97.20%\n",
      "Epoch [248/300], Loss: 0.0119, Accuracy: 97.21%\n",
      "Epoch [249/300], Loss: 0.0113, Accuracy: 97.22%\n",
      "Epoch [250/300], Loss: 0.0116, Accuracy: 97.23%\n",
      "Epoch [251/300], Loss: 0.0127, Accuracy: 97.23%\n",
      "Epoch [252/300], Loss: 0.0129, Accuracy: 97.24%\n",
      "Epoch [253/300], Loss: 0.0126, Accuracy: 97.25%\n",
      "Epoch [254/300], Loss: 0.0117, Accuracy: 97.25%\n",
      "Epoch [255/300], Loss: 0.0162, Accuracy: 97.26%\n",
      "Epoch [256/300], Loss: 0.0930, Accuracy: 97.26%\n",
      "Epoch [257/300], Loss: 0.0330, Accuracy: 97.26%\n",
      "Epoch [258/300], Loss: 0.0211, Accuracy: 97.27%\n",
      "Epoch [259/300], Loss: 0.0157, Accuracy: 97.28%\n",
      "Epoch [260/300], Loss: 0.0151, Accuracy: 97.28%\n",
      "Epoch [261/300], Loss: 0.0118, Accuracy: 97.29%\n",
      "Epoch [262/300], Loss: 0.0122, Accuracy: 97.30%\n",
      "Epoch [263/300], Loss: 0.0115, Accuracy: 97.30%\n",
      "Epoch [264/300], Loss: 0.0116, Accuracy: 97.31%\n",
      "Epoch [265/300], Loss: 0.0113, Accuracy: 97.32%\n",
      "Epoch [266/300], Loss: 0.0113, Accuracy: 97.32%\n",
      "Epoch [267/300], Loss: 0.0112, Accuracy: 97.33%\n",
      "Epoch [268/300], Loss: 0.0112, Accuracy: 97.34%\n",
      "Epoch [269/300], Loss: 0.0114, Accuracy: 97.34%\n",
      "Epoch [270/300], Loss: 0.0114, Accuracy: 97.35%\n",
      "Epoch [271/300], Loss: 0.0111, Accuracy: 97.35%\n",
      "Epoch [272/300], Loss: 0.0110, Accuracy: 97.36%\n",
      "Epoch [273/300], Loss: 0.0112, Accuracy: 97.37%\n",
      "Epoch [274/300], Loss: 0.0234, Accuracy: 97.37%\n",
      "Epoch [275/300], Loss: 0.0563, Accuracy: 97.37%\n",
      "Epoch [276/300], Loss: 0.1225, Accuracy: 97.37%\n",
      "Epoch [277/300], Loss: 0.0290, Accuracy: 97.37%\n",
      "Epoch [278/300], Loss: 0.0143, Accuracy: 97.38%\n",
      "Epoch [279/300], Loss: 0.0123, Accuracy: 97.38%\n",
      "Epoch [280/300], Loss: 0.0116, Accuracy: 97.39%\n",
      "Epoch [281/300], Loss: 0.0120, Accuracy: 97.40%\n",
      "Epoch [282/300], Loss: 0.0123, Accuracy: 97.40%\n",
      "Epoch [283/300], Loss: 0.0114, Accuracy: 97.41%\n",
      "Epoch [284/300], Loss: 0.0119, Accuracy: 97.41%\n",
      "Epoch [285/300], Loss: 0.0118, Accuracy: 97.42%\n",
      "Epoch [286/300], Loss: 0.0120, Accuracy: 97.43%\n",
      "Epoch [287/300], Loss: 0.0114, Accuracy: 97.43%\n",
      "Epoch [288/300], Loss: 0.0112, Accuracy: 97.44%\n",
      "Epoch [289/300], Loss: 0.0126, Accuracy: 97.44%\n",
      "Epoch [290/300], Loss: 0.0640, Accuracy: 97.44%\n",
      "Epoch [291/300], Loss: 0.0297, Accuracy: 97.44%\n",
      "Epoch [292/300], Loss: 0.0169, Accuracy: 97.45%\n",
      "Epoch [293/300], Loss: 0.0198, Accuracy: 97.45%\n",
      "Epoch [294/300], Loss: 0.0217, Accuracy: 97.46%\n",
      "Epoch [295/300], Loss: 0.0188, Accuracy: 97.46%\n",
      "Epoch [296/300], Loss: 0.0131, Accuracy: 97.47%\n",
      "Epoch [297/300], Loss: 0.0117, Accuracy: 97.47%\n",
      "Epoch [298/300], Loss: 0.0116, Accuracy: 97.48%\n",
      "Epoch [299/300], Loss: 0.0112, Accuracy: 97.48%\n",
      "Epoch [300/300], Loss: 0.0111, Accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/300], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a970d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"densenet121_lstm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0958d623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/jpeg": {
       "height": 224,
       "width": 224
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /home/john/Developer/diabetic-retinopathy/images (1).jpeg\n",
      "Predicted Class: Moderate\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tkinter import filedialog\n",
    "from IPython.display import Image as I, display\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "def load_image():\n",
    "    image_path = filedialog.askopenfilename(title=\"Select an image\",\n",
    "                                            filetypes=[(\"Image Files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if not image_path:\n",
    "        print(\"No image selected.\")\n",
    "        return None\n",
    "    \n",
    "    display(I(filename=image_path, width=224, height=224))\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    return img_tensor, image_path\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img_tensor, path = load_image()\n",
    "    if img_tensor is not None:\n",
    "        output = model(img_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        class_names = dataset.classes\n",
    "        print(f\"Image: {path}\")\n",
    "        print(f\"Predicted Class: {class_names[predicted.item()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
