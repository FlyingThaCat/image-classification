{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c276c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Requirement already satisfied: torch in ./.conda/lib/python3.11/site-packages (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in ./.conda/lib/python3.11/site-packages (0.22.1+cu128)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.conda/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.conda/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in ./.conda/lib/python3.11/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in ./.conda/lib/python3.11/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in ./.conda/lib/python3.11/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in ./.conda/lib/python3.11/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in ./.conda/lib/python3.11/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.conda/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.conda/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in ./.conda/lib/python3.11/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in ./.conda/lib/python3.11/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.conda/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.conda/lib/python3.11/site-packages (from triton==3.3.1->torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e35430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eabdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a97d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('./colored_images', transform=transform)\n",
    "\n",
    "class_names = dataset.classes\n",
    "print(f\"Labels: {class_names}\")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=24, pin_memory=True, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=24, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a8e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Developer/diabetic-retinopathy/.conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/john/Developer/diabetic-retinopathy/.conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "feature_extractor = nn.Sequential(\n",
    "    efficientnet.features,\n",
    "    nn.AdaptiveAvgPool2d((7, 7))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d74e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetLSTMClassifier(nn.Module):\n",
    "    def __init__(self, lstm_hidden_size=128, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.features = feature_extractor\n",
    "        self.lstm = nn.LSTM(input_size=49, hidden_size=lstm_hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 1280, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        \n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c72f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetLSTMClassifier(num_classes=5).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fee7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 1.1495, Accuracy: 57.35%\n",
      "Epoch [2/300], Loss: 1.0126, Accuracy: 60.70%\n",
      "Epoch [3/300], Loss: 0.9647, Accuracy: 62.16%\n",
      "Epoch [4/300], Loss: 0.9142, Accuracy: 63.33%\n",
      "Epoch [5/300], Loss: 0.8871, Accuracy: 64.23%\n",
      "Epoch [6/300], Loss: 0.8711, Accuracy: 64.93%\n",
      "Epoch [7/300], Loss: 0.8545, Accuracy: 65.47%\n",
      "Epoch [8/300], Loss: 0.8332, Accuracy: 66.01%\n",
      "Epoch [9/300], Loss: 0.8266, Accuracy: 66.42%\n",
      "Epoch [10/300], Loss: 0.8132, Accuracy: 66.82%\n",
      "Epoch [11/300], Loss: 0.7993, Accuracy: 67.15%\n",
      "Epoch [12/300], Loss: 0.7918, Accuracy: 67.44%\n",
      "Epoch [13/300], Loss: 0.7612, Accuracy: 67.72%\n",
      "Epoch [14/300], Loss: 0.7674, Accuracy: 67.97%\n",
      "Epoch [15/300], Loss: 0.7548, Accuracy: 68.21%\n",
      "Epoch [16/300], Loss: 0.7339, Accuracy: 68.49%\n",
      "Epoch [17/300], Loss: 0.7094, Accuracy: 68.74%\n",
      "Epoch [18/300], Loss: 0.6923, Accuracy: 69.03%\n",
      "Epoch [19/300], Loss: 0.7041, Accuracy: 69.30%\n",
      "Epoch [20/300], Loss: 0.6657, Accuracy: 69.60%\n",
      "Epoch [21/300], Loss: 0.6577, Accuracy: 69.85%\n",
      "Epoch [22/300], Loss: 0.6519, Accuracy: 70.11%\n",
      "Epoch [23/300], Loss: 0.6411, Accuracy: 70.39%\n",
      "Epoch [24/300], Loss: 0.6259, Accuracy: 70.64%\n",
      "Epoch [25/300], Loss: 0.6184, Accuracy: 70.91%\n",
      "Epoch [26/300], Loss: 0.5948, Accuracy: 71.17%\n",
      "Epoch [27/300], Loss: 0.5768, Accuracy: 71.44%\n",
      "Epoch [28/300], Loss: 0.5709, Accuracy: 71.73%\n",
      "Epoch [29/300], Loss: 0.5606, Accuracy: 71.99%\n",
      "Epoch [30/300], Loss: 0.5487, Accuracy: 72.24%\n",
      "Epoch [31/300], Loss: 0.5280, Accuracy: 72.51%\n",
      "Epoch [32/300], Loss: 0.5122, Accuracy: 72.76%\n",
      "Epoch [33/300], Loss: 0.5019, Accuracy: 73.03%\n",
      "Epoch [34/300], Loss: 0.5150, Accuracy: 73.27%\n",
      "Epoch [35/300], Loss: 0.4940, Accuracy: 73.51%\n",
      "Epoch [36/300], Loss: 0.5159, Accuracy: 73.71%\n",
      "Epoch [37/300], Loss: 0.4599, Accuracy: 73.97%\n",
      "Epoch [38/300], Loss: 0.4536, Accuracy: 74.21%\n",
      "Epoch [39/300], Loss: 0.4344, Accuracy: 74.47%\n",
      "Epoch [40/300], Loss: 0.4582, Accuracy: 74.69%\n",
      "Epoch [41/300], Loss: 0.4503, Accuracy: 74.91%\n",
      "Epoch [42/300], Loss: 0.4375, Accuracy: 75.15%\n",
      "Epoch [43/300], Loss: 0.4398, Accuracy: 75.37%\n",
      "Epoch [44/300], Loss: 0.4104, Accuracy: 75.60%\n",
      "Epoch [45/300], Loss: 0.3978, Accuracy: 75.82%\n",
      "Epoch [46/300], Loss: 0.4268, Accuracy: 76.02%\n",
      "Epoch [47/300], Loss: 0.3831, Accuracy: 76.23%\n",
      "Epoch [48/300], Loss: 0.4257, Accuracy: 76.40%\n",
      "Epoch [49/300], Loss: 0.4190, Accuracy: 76.57%\n",
      "Epoch [50/300], Loss: 0.3630, Accuracy: 76.78%\n",
      "Epoch [51/300], Loss: 0.3789, Accuracy: 76.97%\n",
      "Epoch [52/300], Loss: 0.3767, Accuracy: 77.17%\n",
      "Epoch [53/300], Loss: 0.3720, Accuracy: 77.35%\n",
      "Epoch [54/300], Loss: 0.3368, Accuracy: 77.56%\n",
      "Epoch [55/300], Loss: 0.3368, Accuracy: 77.76%\n",
      "Epoch [56/300], Loss: 0.3716, Accuracy: 77.94%\n",
      "Epoch [57/300], Loss: 0.3565, Accuracy: 78.11%\n",
      "Epoch [58/300], Loss: 0.3476, Accuracy: 78.27%\n",
      "Epoch [59/300], Loss: 0.3242, Accuracy: 78.45%\n",
      "Epoch [60/300], Loss: 0.3189, Accuracy: 78.64%\n",
      "Epoch [61/300], Loss: 0.3065, Accuracy: 78.81%\n",
      "Epoch [62/300], Loss: 0.3135, Accuracy: 78.97%\n",
      "Epoch [63/300], Loss: 0.3121, Accuracy: 79.13%\n",
      "Epoch [64/300], Loss: 0.3506, Accuracy: 79.27%\n",
      "Epoch [65/300], Loss: 0.3223, Accuracy: 79.42%\n",
      "Epoch [66/300], Loss: 0.3227, Accuracy: 79.56%\n",
      "Epoch [67/300], Loss: 0.2984, Accuracy: 79.70%\n",
      "Epoch [68/300], Loss: 0.3143, Accuracy: 79.83%\n",
      "Epoch [69/300], Loss: 0.2956, Accuracy: 79.98%\n",
      "Epoch [70/300], Loss: 0.3066, Accuracy: 80.12%\n",
      "Epoch [71/300], Loss: 0.2898, Accuracy: 80.25%\n",
      "Epoch [72/300], Loss: 0.3020, Accuracy: 80.38%\n",
      "Epoch [73/300], Loss: 0.3028, Accuracy: 80.50%\n",
      "Epoch [74/300], Loss: 0.3112, Accuracy: 80.61%\n",
      "Epoch [75/300], Loss: 0.2808, Accuracy: 80.74%\n",
      "Epoch [76/300], Loss: 0.2760, Accuracy: 80.87%\n",
      "Epoch [77/300], Loss: 0.2818, Accuracy: 80.98%\n",
      "Epoch [78/300], Loss: 0.2653, Accuracy: 81.11%\n",
      "Epoch [79/300], Loss: 0.2882, Accuracy: 81.22%\n",
      "Epoch [80/300], Loss: 0.2679, Accuracy: 81.34%\n",
      "Epoch [81/300], Loss: 0.2707, Accuracy: 81.45%\n",
      "Epoch [82/300], Loss: 0.2484, Accuracy: 81.58%\n",
      "Epoch [83/300], Loss: 0.2965, Accuracy: 81.67%\n",
      "Epoch [84/300], Loss: 0.2694, Accuracy: 81.78%\n",
      "Epoch [85/300], Loss: 0.2905, Accuracy: 81.88%\n",
      "Epoch [86/300], Loss: 0.2504, Accuracy: 81.98%\n",
      "Epoch [87/300], Loss: 0.2841, Accuracy: 82.07%\n",
      "Epoch [88/300], Loss: 0.2714, Accuracy: 82.17%\n",
      "Epoch [89/300], Loss: 0.2487, Accuracy: 82.28%\n",
      "Epoch [90/300], Loss: 0.2494, Accuracy: 82.39%\n",
      "Epoch [91/300], Loss: 0.2327, Accuracy: 82.50%\n",
      "Epoch [92/300], Loss: 0.2608, Accuracy: 82.59%\n",
      "Epoch [93/300], Loss: 0.2663, Accuracy: 82.68%\n",
      "Epoch [94/300], Loss: 0.2449, Accuracy: 82.77%\n",
      "Epoch [95/300], Loss: 0.2637, Accuracy: 82.85%\n",
      "Epoch [96/300], Loss: 0.2497, Accuracy: 82.94%\n",
      "Epoch [97/300], Loss: 0.2560, Accuracy: 83.02%\n",
      "Epoch [98/300], Loss: 0.2409, Accuracy: 83.12%\n",
      "Epoch [99/300], Loss: 0.2348, Accuracy: 83.21%\n",
      "Epoch [100/300], Loss: 0.2387, Accuracy: 83.29%\n",
      "Epoch [101/300], Loss: 0.2261, Accuracy: 83.37%\n",
      "Epoch [102/300], Loss: 0.2411, Accuracy: 83.46%\n",
      "Epoch [103/300], Loss: 0.2312, Accuracy: 83.53%\n",
      "Epoch [104/300], Loss: 0.2472, Accuracy: 83.61%\n",
      "Epoch [105/300], Loss: 0.2441, Accuracy: 83.68%\n",
      "Epoch [106/300], Loss: 0.2430, Accuracy: 83.75%\n",
      "Epoch [107/300], Loss: 0.2147, Accuracy: 83.84%\n",
      "Epoch [108/300], Loss: 0.2108, Accuracy: 83.92%\n",
      "Epoch [109/300], Loss: 0.2170, Accuracy: 84.00%\n",
      "Epoch [110/300], Loss: 0.2270, Accuracy: 84.08%\n",
      "Epoch [111/300], Loss: 0.2350, Accuracy: 84.15%\n",
      "Epoch [112/300], Loss: 0.2475, Accuracy: 84.22%\n",
      "Epoch [113/300], Loss: 0.2460, Accuracy: 84.29%\n",
      "Epoch [114/300], Loss: 0.2243, Accuracy: 84.36%\n",
      "Epoch [115/300], Loss: 0.2236, Accuracy: 84.43%\n",
      "Epoch [116/300], Loss: 0.2336, Accuracy: 84.50%\n",
      "Epoch [117/300], Loss: 0.2072, Accuracy: 84.57%\n",
      "Epoch [118/300], Loss: 0.2034, Accuracy: 84.64%\n",
      "Epoch [119/300], Loss: 0.2108, Accuracy: 84.71%\n",
      "Epoch [120/300], Loss: 0.2285, Accuracy: 84.77%\n",
      "Epoch [121/300], Loss: 0.2264, Accuracy: 84.83%\n",
      "Epoch [122/300], Loss: 0.2220, Accuracy: 84.89%\n",
      "Epoch [123/300], Loss: 0.1992, Accuracy: 84.96%\n",
      "Epoch [124/300], Loss: 0.2114, Accuracy: 85.02%\n",
      "Epoch [125/300], Loss: 0.2100, Accuracy: 85.09%\n",
      "Epoch [126/300], Loss: 0.2003, Accuracy: 85.15%\n",
      "Epoch [127/300], Loss: 0.2046, Accuracy: 85.21%\n",
      "Epoch [128/300], Loss: 0.2127, Accuracy: 85.27%\n",
      "Epoch [129/300], Loss: 0.2126, Accuracy: 85.33%\n",
      "Epoch [130/300], Loss: 0.2172, Accuracy: 85.38%\n",
      "Epoch [131/300], Loss: 0.2114, Accuracy: 85.43%\n",
      "Epoch [132/300], Loss: 0.2270, Accuracy: 85.49%\n",
      "Epoch [133/300], Loss: 0.2214, Accuracy: 85.54%\n",
      "Epoch [134/300], Loss: 0.2314, Accuracy: 85.58%\n",
      "Epoch [135/300], Loss: 0.2204, Accuracy: 85.64%\n",
      "Epoch [136/300], Loss: 0.2282, Accuracy: 85.68%\n",
      "Epoch [137/300], Loss: 0.2060, Accuracy: 85.74%\n",
      "Epoch [138/300], Loss: 0.2145, Accuracy: 85.79%\n",
      "Epoch [139/300], Loss: 0.1924, Accuracy: 85.85%\n",
      "Epoch [140/300], Loss: 0.2289, Accuracy: 85.89%\n",
      "Epoch [141/300], Loss: 0.1909, Accuracy: 85.95%\n",
      "Epoch [142/300], Loss: 0.2227, Accuracy: 85.99%\n",
      "Epoch [143/300], Loss: 0.1947, Accuracy: 86.04%\n",
      "Epoch [144/300], Loss: 0.2113, Accuracy: 86.09%\n",
      "Epoch [145/300], Loss: 0.1886, Accuracy: 86.14%\n",
      "Epoch [146/300], Loss: 0.2200, Accuracy: 86.18%\n",
      "Epoch [147/300], Loss: 0.2135, Accuracy: 86.23%\n",
      "Epoch [148/300], Loss: 0.2038, Accuracy: 86.27%\n",
      "Epoch [149/300], Loss: 0.2053, Accuracy: 86.32%\n",
      "Epoch [150/300], Loss: 0.1793, Accuracy: 86.37%\n",
      "Epoch [151/300], Loss: 0.1946, Accuracy: 86.42%\n",
      "Epoch [152/300], Loss: 0.2071, Accuracy: 86.46%\n",
      "Epoch [153/300], Loss: 0.2051, Accuracy: 86.51%\n",
      "Epoch [154/300], Loss: 0.2032, Accuracy: 86.55%\n",
      "Epoch [155/300], Loss: 0.1926, Accuracy: 86.59%\n",
      "Epoch [156/300], Loss: 0.1957, Accuracy: 86.63%\n",
      "Epoch [157/300], Loss: 0.2022, Accuracy: 86.68%\n",
      "Epoch [158/300], Loss: 0.2103, Accuracy: 86.72%\n",
      "Epoch [159/300], Loss: 0.1954, Accuracy: 86.76%\n",
      "Epoch [160/300], Loss: 0.1744, Accuracy: 86.80%\n",
      "Epoch [161/300], Loss: 0.1950, Accuracy: 86.84%\n",
      "Epoch [162/300], Loss: 0.1947, Accuracy: 86.88%\n",
      "Epoch [163/300], Loss: 0.1906, Accuracy: 86.93%\n",
      "Epoch [164/300], Loss: 0.1963, Accuracy: 86.96%\n",
      "Epoch [165/300], Loss: 0.1875, Accuracy: 87.01%\n",
      "Epoch [166/300], Loss: 0.1927, Accuracy: 87.05%\n",
      "Epoch [167/300], Loss: 0.1632, Accuracy: 87.09%\n",
      "Epoch [168/300], Loss: 0.1884, Accuracy: 87.13%\n",
      "Epoch [169/300], Loss: 0.1911, Accuracy: 87.17%\n",
      "Epoch [170/300], Loss: 0.1883, Accuracy: 87.20%\n",
      "Epoch [171/300], Loss: 0.1931, Accuracy: 87.24%\n",
      "Epoch [172/300], Loss: 0.1968, Accuracy: 87.27%\n",
      "Epoch [173/300], Loss: 0.1871, Accuracy: 87.31%\n",
      "Epoch [174/300], Loss: 0.1929, Accuracy: 87.35%\n",
      "Epoch [175/300], Loss: 0.1907, Accuracy: 87.38%\n",
      "Epoch [176/300], Loss: 0.1575, Accuracy: 87.42%\n",
      "Epoch [177/300], Loss: 0.1828, Accuracy: 87.46%\n",
      "Epoch [178/300], Loss: 0.1966, Accuracy: 87.49%\n",
      "Epoch [179/300], Loss: 0.1678, Accuracy: 87.53%\n",
      "Epoch [180/300], Loss: 0.1685, Accuracy: 87.57%\n",
      "Epoch [181/300], Loss: 0.1858, Accuracy: 87.60%\n",
      "Epoch [182/300], Loss: 0.1841, Accuracy: 87.64%\n",
      "Epoch [183/300], Loss: 0.2095, Accuracy: 87.67%\n",
      "Epoch [184/300], Loss: 0.2002, Accuracy: 87.69%\n",
      "Epoch [185/300], Loss: 0.1870, Accuracy: 87.73%\n",
      "Epoch [186/300], Loss: 0.1737, Accuracy: 87.76%\n",
      "Epoch [187/300], Loss: 0.1585, Accuracy: 87.80%\n",
      "Epoch [188/300], Loss: 0.1719, Accuracy: 87.83%\n",
      "Epoch [189/300], Loss: 0.1935, Accuracy: 87.86%\n",
      "Epoch [190/300], Loss: 0.1859, Accuracy: 87.89%\n",
      "Epoch [191/300], Loss: 0.1830, Accuracy: 87.92%\n",
      "Epoch [192/300], Loss: 0.1782, Accuracy: 87.95%\n",
      "Epoch [193/300], Loss: 0.1721, Accuracy: 87.99%\n",
      "Epoch [194/300], Loss: 0.1823, Accuracy: 88.02%\n",
      "Epoch [195/300], Loss: 0.1572, Accuracy: 88.05%\n",
      "Epoch [196/300], Loss: 0.1808, Accuracy: 88.08%\n",
      "Epoch [197/300], Loss: 0.1926, Accuracy: 88.11%\n",
      "Epoch [198/300], Loss: 0.1636, Accuracy: 88.14%\n",
      "Epoch [199/300], Loss: 0.1944, Accuracy: 88.17%\n",
      "Epoch [200/300], Loss: 0.1521, Accuracy: 88.20%\n",
      "Epoch [201/300], Loss: 0.1744, Accuracy: 88.23%\n",
      "Epoch [202/300], Loss: 0.1813, Accuracy: 88.25%\n",
      "Epoch [203/300], Loss: 0.1766, Accuracy: 88.28%\n",
      "Epoch [204/300], Loss: 0.1881, Accuracy: 88.31%\n",
      "Epoch [205/300], Loss: 0.1767, Accuracy: 88.34%\n",
      "Epoch [206/300], Loss: 0.1666, Accuracy: 88.37%\n",
      "Epoch [207/300], Loss: 0.1560, Accuracy: 88.40%\n",
      "Epoch [208/300], Loss: 0.1605, Accuracy: 88.43%\n",
      "Epoch [209/300], Loss: 0.1687, Accuracy: 88.45%\n",
      "Epoch [210/300], Loss: 0.1719, Accuracy: 88.48%\n",
      "Epoch [211/300], Loss: 0.1593, Accuracy: 88.51%\n",
      "Epoch [212/300], Loss: 0.1594, Accuracy: 88.54%\n",
      "Epoch [213/300], Loss: 0.1751, Accuracy: 88.56%\n",
      "Epoch [214/300], Loss: 0.1637, Accuracy: 88.59%\n",
      "Epoch [215/300], Loss: 0.1789, Accuracy: 88.61%\n",
      "Epoch [216/300], Loss: 0.1556, Accuracy: 88.64%\n",
      "Epoch [217/300], Loss: 0.1543, Accuracy: 88.67%\n",
      "Epoch [218/300], Loss: 0.1742, Accuracy: 88.70%\n",
      "Epoch [219/300], Loss: 0.1691, Accuracy: 88.72%\n",
      "Epoch [220/300], Loss: 0.1799, Accuracy: 88.74%\n",
      "Epoch [221/300], Loss: 0.1718, Accuracy: 88.77%\n",
      "Epoch [222/300], Loss: 0.1523, Accuracy: 88.80%\n",
      "Epoch [223/300], Loss: 0.1610, Accuracy: 88.82%\n",
      "Epoch [224/300], Loss: 0.1935, Accuracy: 88.84%\n",
      "Epoch [225/300], Loss: 0.1592, Accuracy: 88.87%\n",
      "Epoch [226/300], Loss: 0.1499, Accuracy: 88.89%\n",
      "Epoch [227/300], Loss: 0.1670, Accuracy: 88.92%\n",
      "Epoch [228/300], Loss: 0.1695, Accuracy: 88.94%\n",
      "Epoch [229/300], Loss: 0.1776, Accuracy: 88.96%\n",
      "Epoch [230/300], Loss: 0.1626, Accuracy: 88.98%\n",
      "Epoch [231/300], Loss: 0.1541, Accuracy: 89.01%\n",
      "Epoch [232/300], Loss: 0.1565, Accuracy: 89.03%\n",
      "Epoch [233/300], Loss: 0.1579, Accuracy: 89.06%\n",
      "Epoch [234/300], Loss: 0.1552, Accuracy: 89.08%\n",
      "Epoch [235/300], Loss: 0.1867, Accuracy: 89.10%\n",
      "Epoch [236/300], Loss: 0.1633, Accuracy: 89.12%\n",
      "Epoch [237/300], Loss: 0.1526, Accuracy: 89.15%\n",
      "Epoch [238/300], Loss: 0.1676, Accuracy: 89.17%\n",
      "Epoch [239/300], Loss: 0.1652, Accuracy: 89.19%\n",
      "Epoch [240/300], Loss: 0.1834, Accuracy: 89.21%\n",
      "Epoch [241/300], Loss: 0.1606, Accuracy: 89.23%\n",
      "Epoch [242/300], Loss: 0.1604, Accuracy: 89.26%\n",
      "Epoch [243/300], Loss: 0.1860, Accuracy: 89.27%\n",
      "Epoch [244/300], Loss: 0.1633, Accuracy: 89.29%\n",
      "Epoch [245/300], Loss: 0.1492, Accuracy: 89.32%\n",
      "Epoch [246/300], Loss: 0.1696, Accuracy: 89.34%\n",
      "Epoch [247/300], Loss: 0.1620, Accuracy: 89.36%\n",
      "Epoch [248/300], Loss: 0.1715, Accuracy: 89.38%\n",
      "Epoch [249/300], Loss: 0.1475, Accuracy: 89.40%\n",
      "Epoch [250/300], Loss: 0.1523, Accuracy: 89.42%\n",
      "Epoch [251/300], Loss: 0.1662, Accuracy: 89.44%\n",
      "Epoch [252/300], Loss: 0.1604, Accuracy: 89.46%\n",
      "Epoch [253/300], Loss: 0.1605, Accuracy: 89.48%\n",
      "Epoch [254/300], Loss: 0.1481, Accuracy: 89.50%\n",
      "Epoch [255/300], Loss: 0.1593, Accuracy: 89.52%\n",
      "Epoch [256/300], Loss: 0.1589, Accuracy: 89.54%\n",
      "Epoch [257/300], Loss: 0.1654, Accuracy: 89.56%\n",
      "Epoch [258/300], Loss: 0.1777, Accuracy: 89.57%\n",
      "Epoch [259/300], Loss: 0.1653, Accuracy: 89.59%\n",
      "Epoch [260/300], Loss: 0.1814, Accuracy: 89.61%\n",
      "Epoch [261/300], Loss: 0.1537, Accuracy: 89.63%\n",
      "Epoch [262/300], Loss: 0.1594, Accuracy: 89.65%\n",
      "Epoch [263/300], Loss: 0.1544, Accuracy: 89.67%\n",
      "Epoch [264/300], Loss: 0.1552, Accuracy: 89.68%\n",
      "Epoch [265/300], Loss: 0.1749, Accuracy: 89.70%\n",
      "Epoch [266/300], Loss: 0.1524, Accuracy: 89.72%\n",
      "Epoch [267/300], Loss: 0.1526, Accuracy: 89.74%\n",
      "Epoch [268/300], Loss: 0.1530, Accuracy: 89.76%\n",
      "Epoch [269/300], Loss: 0.1538, Accuracy: 89.78%\n",
      "Epoch [270/300], Loss: 0.1546, Accuracy: 89.79%\n",
      "Epoch [271/300], Loss: 0.1573, Accuracy: 89.81%\n",
      "Epoch [272/300], Loss: 0.1695, Accuracy: 89.83%\n",
      "Epoch [273/300], Loss: 0.1682, Accuracy: 89.84%\n",
      "Epoch [274/300], Loss: 0.1619, Accuracy: 89.86%\n",
      "Epoch [275/300], Loss: 0.1431, Accuracy: 89.88%\n",
      "Epoch [276/300], Loss: 0.1549, Accuracy: 89.90%\n",
      "Epoch [277/300], Loss: 0.1557, Accuracy: 89.91%\n",
      "Epoch [278/300], Loss: 0.1345, Accuracy: 89.94%\n",
      "Epoch [279/300], Loss: 0.1652, Accuracy: 89.95%\n",
      "Epoch [280/300], Loss: 0.1340, Accuracy: 89.97%\n",
      "Epoch [281/300], Loss: 0.1258, Accuracy: 89.99%\n",
      "Epoch [282/300], Loss: 0.1397, Accuracy: 90.01%\n",
      "Epoch [283/300], Loss: 0.1617, Accuracy: 90.03%\n",
      "Epoch [284/300], Loss: 0.1546, Accuracy: 90.04%\n",
      "Epoch [285/300], Loss: 0.1627, Accuracy: 90.06%\n",
      "Epoch [286/300], Loss: 0.1265, Accuracy: 90.08%\n",
      "Epoch [287/300], Loss: 0.1628, Accuracy: 90.09%\n",
      "Epoch [288/300], Loss: 0.1565, Accuracy: 90.11%\n",
      "Epoch [289/300], Loss: 0.1462, Accuracy: 90.13%\n",
      "Epoch [290/300], Loss: 0.1531, Accuracy: 90.14%\n",
      "Epoch [291/300], Loss: 0.1405, Accuracy: 90.16%\n",
      "Epoch [292/300], Loss: 0.1651, Accuracy: 90.17%\n",
      "Epoch [293/300], Loss: 0.1767, Accuracy: 90.18%\n",
      "Epoch [294/300], Loss: 0.1575, Accuracy: 90.20%\n",
      "Epoch [295/300], Loss: 0.1324, Accuracy: 90.22%\n",
      "Epoch [296/300], Loss: 0.1469, Accuracy: 90.23%\n",
      "Epoch [297/300], Loss: 0.1455, Accuracy: 90.25%\n",
      "Epoch [298/300], Loss: 0.1337, Accuracy: 90.27%\n",
      "Epoch [299/300], Loss: 0.1297, Accuracy: 90.28%\n",
      "Epoch [300/300], Loss: 0.1363, Accuracy: 90.30%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/300], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a970d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"EfficientNetB0_no_grad_lstm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0958d623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/jpeg": {
       "height": 224,
       "width": 224
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /home/john/Developer/diabetic-retinopathy/images.jpeg\n",
      "Predicted Class: Severe\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tkinter import filedialog\n",
    "from IPython.display import Image as I, display\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "def load_image():\n",
    "    image_path = filedialog.askopenfilename(title=\"Select an image\",\n",
    "                                            filetypes=[(\"Image Files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if not image_path:\n",
    "        print(\"No image selected.\")\n",
    "        return None\n",
    "    \n",
    "    display(I(filename=image_path, width=224, height=224))\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    return img_tensor, image_path\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img_tensor, path = load_image()\n",
    "    if img_tensor is not None:\n",
    "        output = model(img_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        class_names = dataset.classes\n",
    "        print(f\"Image: {path}\")\n",
    "        print(f\"Predicted Class: {class_names[predicted.item()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
